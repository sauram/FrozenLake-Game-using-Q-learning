{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "action_space_size= env.action_space.n\n",
    "state_space_size= env.observation_space.n\n",
    "\n",
    "q_table= np.zeros((state_space_size, action_space_size))\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes=10000\n",
    "max_steps_per_episode=1000\n",
    "\n",
    "learning_rate= 0.01\n",
    "discount_factor= 0.99\n",
    "\n",
    "max_exploration = 1.0\n",
    "min_exploration = 0.01\n",
    "exploration_rate_decay= 0.001\n",
    "exploration = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Average reward per thousand episodes********\n",
      "\n",
      "1000 :  0.04\n",
      "2000 :  0.158\n",
      "3000 :  0.379\n",
      "4000 :  0.541\n",
      "5000 :  0.63\n",
      "6000 :  0.648\n",
      "7000 :  0.707\n",
      "8000 :  0.69\n",
      "9000 :  0.697\n",
      "10000 :  0.667\n"
     ]
    }
   ],
   "source": [
    "rewards_all_episodes= []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state= env.reset()\n",
    "    done=False\n",
    "    reward_current_episode=0\n",
    "    for step in range(max_steps_per_episode):\n",
    "        exploration_threshold= random.uniform(0,1)\n",
    "        if(exploration_threshold > exploration):\n",
    "            action=np.argmax(q_table[state, : ])\n",
    "        else:\n",
    "            action= env.action_space.sample()\n",
    "        new_state, reward, done, info= env.step(action)\n",
    "        \n",
    "        q_table[state,action]= q_table[state,action]*(1-learning_rate) + learning_rate*(reward + discount_factor* np.max(q_table[new_state,:]))\n",
    "        \n",
    "        state=new_state\n",
    "        reward_current_episode+=reward;\n",
    "        if done==True:\n",
    "            break\n",
    "    exploration= min_exploration + (max_exploration-min_exploration)*np.exp(-exploration_rate_decay*episode)\n",
    "    rewards_all_episodes.append(reward_current_episode)\n",
    "    \n",
    "rewards_per_thousand_episodes = np.split(np.array(rewards_all_episodes),num_episodes/1000)\n",
    "count = 1000\n",
    "\n",
    "print(\"********Average reward per thousand episodes********\\n\")\n",
    "for r in rewards_per_thousand_episodes:\n",
    "    print(count, \": \", str(sum(r/1000)))\n",
    "    count += 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.52979785  0.51608726  0.51768394  0.51597781]\n",
      " [ 0.41709023  0.3927828   0.42606525  0.49023609]\n",
      " [ 0.46009614  0.46395608  0.4605671   0.46790899]\n",
      " [ 0.41598526  0.40711586  0.35537133  0.45587807]\n",
      " [ 0.54676095  0.40765809  0.41314075  0.36674873]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.33873035  0.20422533  0.32001094  0.21772987]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.38883228  0.41585004  0.4041694   0.58542598]\n",
      " [ 0.44800037  0.64588799  0.49600742  0.47884976]\n",
      " [ 0.59772181  0.51265778  0.41592771  0.36323832]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.43435434  0.528442    0.74177134  0.53072444]\n",
      " [ 0.7763921   0.87364169  0.81953766  0.81269795]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "Reached Goal\n"
     ]
    }
   ],
   "source": [
    "for episode in range(3):\n",
    "    state=env.reset()\n",
    "    done=False\n",
    "    time.sleep(1)\n",
    "    print(episode)\n",
    "    for step in range(max_steps_per_episode):\n",
    "        clear_output(wait=True)\n",
    "        env.render()\n",
    "        time.sleep(0.3)\n",
    "        action= np.argmax(q_table[state, :])\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            clear_output(wait=True)\n",
    "            env.render()\n",
    "            if reward==1:\n",
    "                print(\"Reached Goal\")\n",
    "                time.sleep(3)\n",
    "            else:\n",
    "                print(\"Fell in hole\")\n",
    "                time.sleep(3)\n",
    "            clear_output(wait=True)\n",
    "            break\n",
    "        state= new_state\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
